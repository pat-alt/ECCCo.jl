---
title: 'Author Response'
format: commonmark
bibliography: ../bib.bib
---

# Author Response

Following the reviews we received for NeurIPS we have taken substantial measures to address reviewer concerns both during the initial rebuttal period and beyond. 

## Additional Datasets

A common concern across reviewers was limited evaluation on real-world datasets. While the scope of our initial experiments was already well in line with the existing related literature, we agreed with the reviewers and have added two additional tabular datasets from the social sciences domain as well as one additional dataset from the vision domain. As mentioned in the paper, we have resorted to datasets commonly used in the literature. 

### A note on image datasets

Related work on plausibility of counterfactuals has largely relied on small image datasets like *MNIST* [@dhurandhar2018explanations,@schut2021generating]. This may be due to the fact that generating counterfactuals for high-dimensional input data is computationally very challenging. An exception to this rule is the work on *REVISE* [@joshi2019realistic], which uses a larger image dataset. *REVISE* is suitable for this task, because it maps counterfactuals to a lower-dimensional latent space. Similarly, our proposed *ECCCo+* should also be applicable to high-dimensional input data. In our benchmarks, however, we include other generators that search directly in the input space. Since our benchmarks required us to generate a very large number of counterfactuals, it was not at this time feasible to include larger image datasets. That is despite our best efforts to optimize the code and parallelize the computations through multi-threading and multi-processing on a high-performance computing cluster.

## Constraining Energy Directly

In our initial work we used our unfaithfulness metric directly as a penalty term in *ECCCo*'s counterfactual search objective. This generally achieves the highest levels of faithfulness but it has several disadvantages, some of which were pointed out by the reviewers. Our new approach constrains the energy directly, which is more theoretically grounded and leads to better results across the board. It also addresses the following reviewer concerns:

### Results are biased with respect to unfaithfulness metric

One reviewer raised concern about the fact the using the unfaithfulness metric as a penalty biases the results. This is a valid concern which we have addressed now.

### Counterfactuals looked homogeneous

Another reviewer pointed out that the counterfactuals generated by *ECCCo* looked homogeneous, which is also a valid concern. The observed homogeneity most likely stemmed form the fact that the samples generated through SGLD for the underlying models were fairly homogenous. With our new approach we no longer rely on SGLD samples and the homogeneity issue is no longer present. 

### Closeness criterium violated

A related concern was that large perturbations induced by *ECCCo* seemed to violate the closeness criterium. As we discuss in the paper, our findings do not suggest that *ECCCo* yields unnecessarily costly counterfactuals. Indeed, with reference to the vision data, *ECCCo* seems to keep useful parts of the factual largely in tact, which reduces costs. As we already argued during the rebuttal and in the paper, additional costs cannot be avoided entirely when faithfulness and plausibility are prioritized. This applies to *ECCCo* as much as to other generators like *REVISE*.

### Sampling Overhead



1. Applied to additional commonly used tabular real-world datasets
2. Constraining energy directly
   1. Better results across the board, in particular for image data
   2. Derived from JEM loss function -> more theoretically grounded
   3. No sampling overhead.
   4. Energy does not depend on differentiability.
   5. Benchmarks no longer biased with respect to unfaithfulness metric (addressing reviewer concern).
3. Counterfactual explanations do not scale well to high-dimensional input data
   1. We have added native support for multi-processing and multi-threading.
   2. We have run more extensive experiments including fine-tuning hyperparameter choices.
   3. For image data we use PCA to map counterfactuals to a smaller dimenionsional latent space, which not only reduces costs of gradient computations but also leads to higher plausibility.
   4. PCA is much less costly and interventionist than a VAE: pricipal component merely represent variation in the data; nothing else about the data is learned by the surrogate. 
      1. ECCCo-$\Delta$ (latent) remains faithful, although not as faithful as standard ECCCo-$\Delta$.
4. We have revisited the mathematical notation.
5. We have moved the introduction of conformal prediction forward and added more detail in line with reviewer feedback.
6. We have extended the limitations section. 
7. Distance metric
   1. We have revisited the distance metrics and decided to use the L2 Norm for plausibility and faithfulness
   2. Orginially, we used the L1 Norm in line with how the the closeness criterium is commonly evaluated. But in this context the L1 Norm implicitly addresses the desire for sparsity.
   3. In the case of image data, we investigated various additional distance metrics:
      1. Cosine similarity
      2. Euclidean distance
      3. Ultimately we chose to rely on structural dissimilarity.
   