Thank you! In this individual response, we will refer back to the main points discussed in the global response where relevant and discuss any other specific points the reviewer has raised.

We will jump straight to the questions that have been raised. 

Firstly, concerning the limited set of models and real-world datasets (**Question 1** and **Question 3**), please refer to **Point 1** and **Point 2** in the global response, respectively. 

Concerning generalisability (**Question 2**), our approach should generalise to any classifier that is differentiable with respect to inputs, consistent with other gradient-based counterfactual generators (Equation 1). Our actual implementation is currently compatible with neural networks trained in Julia and has experimental support for `torch` trained in either Python or R. Even though it is possible to generate counterfactuals for non-differentiable models, it is not immediately obvious to us how SGLD can be applied in this context. An interesting question for future research would be if other scalable and gradient-free methods can be used to sample from the conditional distribution learned by the model. 

Finally, concerning connections to causal abstractions and causal explanations (**Question 4**), this is an interesting thought. We would have to think about this more, but there is a possible link to the work by Karimi et al. on counterfactuals through interventions as opposed to perturbations (references in the paper). An idea could be to use the abstracted causal graph as our sampler for ECCCo (instead of SGLD). Combining the approach proposed by Karimi et al. with ideas underlying ECCCo, one could then generate counterfactuals that faithfully describe the causal graph learned by the model, instead of generating counterfactuals that comply with prior causal knowledge. We think this may go beyond the scope of our paper but would be happy to add this to section 7.