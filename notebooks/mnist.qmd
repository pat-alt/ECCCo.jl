```{julia}
include("notebooks/setup.jl")
eval(setup_notebooks)
```

# MNIST

```{julia}
function pre_process(x; noise::Float32=0.03f0)
    系 = Float32.(randn(size(x)) * noise)
    x = @.(2 * x - 1) .+ 系
    return x
end
```

```{julia}
# Data:
n_obs = 10000
counterfactual_data = load_mnist(n_obs)
X, y = CounterfactualExplanations.DataPreprocessing.unpack_data(counterfactual_data)
X = pre_process.(X)
X = table(permutedims(X))
labels = counterfactual_data.output_encoder.labels
input_dim, n_obs = size(counterfactual_data.X)
n_digits = Int(sqrt(input_dim))
output_dim = length(unique(labels))
```

First, let's create a couple of image classifier architectures:

```{julia}
# Model parameters:
epochs = 100
batch_size = minimum([Int(round(n_obs/10)), 128])
n_hidden = 32
activation = Flux.swish
# builder = MLJFlux.@builder Flux.Chain(
#     Dense(n_in, n_hidden, activation),
#     Dense(n_hidden, n_hidden, activation),
#     Dense(n_hidden, n_hidden, activation),
#     # BatchNorm(n_hidden, activation),
#     # Dense(n_hidden, n_hidden),
#     # BatchNorm(n_hidden, activation),
#     Dense(n_hidden, n_out),
# )
builder = MLJFlux.Short(n_hidden=n_hidden, dropout=0.1, =activation)
# builder = MLJFlux.MLP(
#     hidden=(
#         n_hidden,
#         n_hidden,
#         n_hidden,
#     ), 
#     =activation
# )
伪 = [1.0,1.0,1e-1]

# Simple MLP:
mlp = NeuralNetworkClassifier(
    builder=builder, 
    epochs=epochs,
    batch_size=batch_size,
)

# Joint Energy Model:
x = Uniform(-1,1)
y = Categorical(ones(output_dim) ./ output_dim)
sampler = ConditionalSampler(
    x, y, 
    input_size=(input_dim,), 
    batch_size=10
)
jem = JointEnergyClassifier(
    sampler;
    builder=builder,
    batch_size=batch_size,
    finaliser=x -> x,
    loss=Flux.Losses.logitcrossentropy,
    jem_training_params=(
        伪=伪,verbosity=10,
        # use_gen_loss=false,
        # use_reg_loss=false,
    ),
    sampling_steps=20,
    epochs=epochs,
)

# Deep Ensemble:
mlp_ens = EnsembleModel(model=mlp, n=5)
```

```{julia}
cov = .95
conf_model = conformal_model(jem; method=:adaptive_inductive, coverage=cov)
mach = machine(conf_model, X, labels)
fit!(mach)
M = ECCCo.ConformalModel(mach.model, mach.fitresult)
```

```{julia}
if mach.model.model isa JointEnergyModels.JointEnergyClassifier
    jem = mach.model.model.jem
    n_iter = 500
    _w = 1500
    plts = []
    neach = 10
    for i in 1:10
        x = jem.sampler(jem.chain, jem.sampling_rule; niter=n_iter, n_samples=neach, y=i)
        plts_i = []
        for j in 1:size(x, 2)
            xj = x[:,j]
            xj = reshape(xj, (n_digits, n_digits))
            plts_i = [plts_i..., Plots.heatmap(rotl90(xj), axis=nothing, cb=false)]
        end
        plt = Plots.plot(plts_i..., size=(_w,0.10*_w), layout=(1,10))
        plts = [plts..., plt]
    end
    plt = Plots.plot(plts..., size=(_w,_w), layout=(10,1))
    display(plt)
end
```

```{julia}
test_data = load_mnist_test()
f1 = CounterfactualExplanations.Models.model_evaluation(M, test_data)
println("F1 score (test): $(round(f1,digits=3))")
```

```{julia}
# Random.seed!(1234)

# Set up search:
factual_label = 8
x = reshape(counterfactual_data.X[:,rand(findall(predict_label(M, counterfactual_data).==factual_label))],input_dim,1)
target = 3
factual = predict_label(M, counterfactual_data, x)[1]
纬 = 0.5
T = 100

# Generate counterfactual using generic generator:
generator = GenericGenerator(opt=Flux.Optimise.Adam(),)
ce_wachter = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
)

generator = GreedyGenerator(畏=1.0)
ce_jsma = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
)

# ECCCo:
位=[0.0,1.0]
temp=0.01

# Generate counterfactual using ECCCo generator:
generator = CCEGenerator(
    位=位, 
    temp=temp, 
    opt=Flux.Optimise.Adam(),
)
ce_conformal = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
    converge_when=:generator_conditions,
)

# Generate counterfactual using ECCCo generator:
generator = CCEGenerator(
    位=位, 
    temp=temp, 
    opt=CounterfactualExplanations.Generators.JSMADescent(畏=1.0),
)
ce_conformal_jsma = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
    converge_when=:generator_conditions,
)

# Plot:
p1 = Plots.plot(
    convert2image(MNIST, reshape(x,28,28)),
    axis=nothing, 
    size=(img_height, img_height),
    title="Factual"
)
plts = [p1]

ces = [ce_wachter, ce_conformal, ce_jsma, ce_conformal_jsma]
_names = ["Wachter", "ECCCo", "JSMA", "ECCCo-JSMA"]
for x in zip(ces, _names)
    ce, _name = (x[1],x[2])
    x = CounterfactualExplanations.counterfactual(ce)
    _phat = target_probs(ce)
    _title = "$_name (p=$(round(_phat[1]; digits=3)))"
    plt = Plots.plot(
        convert2image(MNIST, reshape(x,28,28)),
        axis=nothing, 
        size=(img_height, img_height),
        title=_title
    )
    plts = [plts..., plt]
end
plt = Plots.plot(plts...; size=(img_height*length(plts),img_height), layout=(1,length(plts)))
display(plt)
savefig(plt, joinpath(www_path, "cce_mnist.png"))
```

```{julia}
# Random.seed!(1234)

# Set up search:
factual_label = 8
x = reshape(counterfactual_data.X[:,rand(findall(predict_label(M, counterfactual_data).==factual_label))],input_dim,1)
target = 3
factual = predict_label(M, counterfactual_data, x)[1]
纬 = 0.5
T = 100

# Generate counterfactual using generic generator:
generator = GenericGenerator(opt=Flux.Optimise.Adam(),)
ce_wachter = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
)

generator = GreedyGenerator(畏=1.0)
ce_jsma = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
)

# ECCCo:
位=[0.0,1.0,1.0]
temp=0.01

# Generate counterfactual using ECCCo generator:
generator = ECCCoGenerator(
    位=位, 
    temp=temp, 
    opt=Flux.Optimise.Adam(),
)
ce_conformal = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
    converge_when=:generator_conditions,
)

# Generate counterfactual using ECCCo generator:
generator = ECCCoGenerator(
    位=位, 
    temp=temp, 
    opt=CounterfactualExplanations.Generators.JSMADescent(畏=1.0),
)
ce_conformal_jsma = generate_counterfactual(
    x, target, counterfactual_data, M, generator; 
    decision_threshold=纬, max_iter=T,
    initialization=:identity,
    converge_when=:generator_conditions,
)

# Plot:
p1 = Plots.plot(
    convert2image(MNIST, reshape(x,28,28)),
    axis=nothing, 
    size=(img_height, img_height),
    title="Factual"
)
plts = [p1]

ces = [ce_wachter, ce_conformal, ce_jsma, ce_conformal_jsma]
_names = ["Wachter", "ECCCo", "JSMA", "ECCCo-JSMA"]
for x in zip(ces, _names)
    ce, _name = (x[1],x[2])
    x = CounterfactualExplanations.counterfactual(ce)
    _phat = target_probs(ce)
    _title = "$_name (p=$(round(_phat[1]; digits=3)))"
    plt = Plots.plot(
        convert2image(MNIST, reshape(x,28,28)),
        axis=nothing, 
        size=(img_height, img_height),
        title=_title
    )
    plts = [plts..., plt]
end
plt = Plots.plot(plts...; size=(img_height*length(plts),img_height), layout=(1,length(plts)))
display(plt)
savefig(plt, joinpath(www_path, "cce_mnist.png"))
```

## Benchmark

```{julia}
# Benchmark generators:
generators = Dict(
    :wachter => GenericGenerator(opt=opt, 位=l2_位),
    :revise => REVISEGenerator(opt=opt, 位=l2_位),
    :greedy => GreedyGenerator(),
)

# Conformal Models: 


# Measures:
measures = [
    CounterfactualExplanations.distance,
    ECCCo.distance_from_energy,
    ECCCo.distance_from_targets,
    CounterfactualExplanations.validity,
]
```